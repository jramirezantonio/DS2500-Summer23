{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f64b9c1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "00'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46053ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hafid\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "nltk.download('punkt')\n",
    "from nltk.chat.util import Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01595771",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'courses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Preprocess course data\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m course_titles \u001b[38;5;241m=\u001b[39m [courses[course][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m course \u001b[38;5;129;01min\u001b[39;00m \u001b[43mcourses\u001b[49m]\n\u001b[0;32m      3\u001b[0m course_descriptions \u001b[38;5;241m=\u001b[39m [courses[course][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m course \u001b[38;5;129;01min\u001b[39;00m courses]\n\u001b[0;32m      4\u001b[0m course_prerequisites \u001b[38;5;241m=\u001b[39m [courses[course][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprerequisites\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m course \u001b[38;5;129;01min\u001b[39;00m courses]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'courses' is not defined"
     ]
    }
   ],
   "source": [
    "# Preprocess course data\n",
    "course_titles = [courses[course]['title'] for course in courses]\n",
    "course_descriptions = [courses[course]['description'] for course in courses]\n",
    "course_prerequisites = [courses[course]['prerequisites'] for course in courses]\n",
    "course_corequisites = [courses[course]['corequisites'] for course in courses]\n",
    "course_attributes = [courses[course]['attributes'] for course in courses]\n",
    "# print(course_attributes)\n",
    "\n",
    "# Example user query\n",
    "user_query = \"machine learning\"\n",
    "# \"I want to take an intermediate level course on machine learning\"\n",
    "\n",
    "# Tokenize user query\n",
    "tokens = word_tokenize(user_query)\n",
    "\n",
    "# Perform filtering based on user query\n",
    "filtered_courses = []\n",
    "for course in courses:\n",
    "    # Filter based on course description\n",
    "        if all(token.lower() in courses[course][\"description\"].lower() for token in tokens):\n",
    "            filtered_courses.append(course)\n",
    "\n",
    "for token in tokens:\n",
    "    print(token.lower())\n",
    "            \n",
    "# Print the filtered course recommendations\n",
    "if filtered_courses:\n",
    "    print(\"Course Recommendations:\")\n",
    "    for course in filtered_courses:\n",
    "        print(course)\n",
    "else:\n",
    "    print(\"No matching courses found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c21d9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6471c571",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a60998a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_data(filename):\n",
    "    courses = {}\n",
    "    with open(filename, 'r') as infile:\n",
    "        for line in infile:\n",
    "            data = line.strip().split('\\n')\n",
    "            if '' not in data:\n",
    "                if data[0].startswith('DS'):\n",
    "                    course_dict = {}\n",
    "                    course_title = data[0].split(\".\")[0]\n",
    "                    course_dict['title'] = data[0]\n",
    "                    courses[course_title] = course_dict\n",
    "                    courses[course_title]['prerequisites'] = \"\"\n",
    "                    courses[course_title]['corequisites'] = \"\"\n",
    "                    courses[course_title]['attributes'] = \"\"\n",
    "                    courses[course_title]['description'] = \"\"\n",
    "                elif data[0].startswith('Prerequisite(s):'):\n",
    "                    courses[course_title]['prerequisites'] = data[0]\n",
    "                elif data[0].startswith('Corequisite(s):'):\n",
    "                    courses[course_title]['corequisites'] = data[0]\n",
    "                elif data[0].startswith('Attribute(s):'):\n",
    "                    courses[course_title]['attributes'] = data[0]\n",
    "                else:\n",
    "                    courses[course_title]['description'] = data[0]\n",
    "    return courses\n",
    "# print(courses['DS 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0825d48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "import re\n",
    "import random \n",
    "\n",
    "def make_word_list(paragraph):\n",
    "    \"\"\"\n",
    "    Function: Creates a list of words from speeches\n",
    "    Parameters: speeches, list of strings\n",
    "    Returns: List of lists of strings\n",
    "    \"\"\"\n",
    "    word = \"\"\n",
    "    word_list = []\n",
    "    paragraph = paragraph.strip() # Removing leading/trailing whitespace\n",
    "    paragraph = re.sub('\\[.*\\]', '', paragraph) # Remove character heading\n",
    "    paragraph = re.sub('[^\\w\\s]', '', paragraph) # Remove punctuation\n",
    "    paragraph = paragraph.lower() # Convert to lower case\n",
    "    paragraph = paragraph + \" \" # To prevent skipping last word\n",
    "    for char in paragraph:\n",
    "        if char != \" \":\n",
    "            word = word+char\n",
    "        elif char == \" \" and word != \"\":\n",
    "            word_list.append(word)\n",
    "            word = \"\"\n",
    "    return word_list\n",
    "\n",
    "\n",
    "def remove_stop_words(stop_words, paragraph):\n",
    "    \"\"\"\n",
    "    Function: Removes common stop words\n",
    "    Parameters: stop_words, list of strings of common stop words, speeches, list of strings\n",
    "    Returns: List of lists of strings\n",
    "    \"\"\"\n",
    "    word_list = make_word_list(paragraph)\n",
    "    for i in range(len(word_list)-1, -1, -1):\n",
    "        if word_list[i] in stop_words:\n",
    "            del word_list[i]\n",
    "    return word_list\n",
    "\n",
    "\n",
    "# Convert a list of words to a word vector (code from class)\n",
    "def vectorize(words, unique):\n",
    "    return [1 if word in words else 0 for word in unique]\n",
    "\n",
    "\n",
    "# Vector functions\n",
    "def mag(v):\n",
    "    \"\"\" magnitude of a vector \"\"\"\n",
    "    return sum([i **2 for i in v]) ** 0.5\n",
    "\n",
    "\n",
    "def dot(u,v):\n",
    "    \"\"\" dot product of two vectors \"\"\"\n",
    "    return sum([ui * vi for ui, vi in zip(u,v)])\n",
    "   \n",
    "def cosine_similarity(u, v):\n",
    "    cos_theta = dot(u,v)/(mag(u)*mag(v))\n",
    "    return cos_theta\n",
    "\n",
    "\n",
    "courses = sort_data('DSCourses.txt')\n",
    "# print(courses)\n",
    "\n",
    "def recommendation(user_input):\n",
    "    clean_course_descriptions = {}\n",
    "    for key in courses.keys():\n",
    "        clean_course_descriptions[key] = remove_stop_words(stop_words, courses[key]['description'])\n",
    "    unique = list(set(val for st in clean_course_descriptions.values() for val in st))\n",
    "    # user_input = \"I want to take an introductory data science course\"\n",
    "    clean_user_input = remove_stop_words(stop_words, user_input)\n",
    "    u = vectorize(clean_user_input, unique)\n",
    "    recommended_courses = []\n",
    "    for course in clean_course_descriptions.keys():\n",
    "        v = vectorize(clean_course_descriptions[course], unique)\n",
    "        cos_sim = cosine_similarity(u, v)\n",
    "        if cos_sim > 0:\n",
    "            recommended_courses.append(course)\n",
    "    return recommended_courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab7c449",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(recommendation(\"I want to take an advanced machine learning course\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "98fa58c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = [\n",
    "    \"Hello! How can I help you today?\",\n",
    "    \"What's on your mind?\",\n",
    "    \"I'm here to assist you. What do you need?\",\n",
    "    \"How can I assist you?\",\n",
    "    \"What can I help you with?\",\n",
    "]\n",
    "\n",
    "def chatbot_response(user_input):\n",
    "    user_input = user_input.lower()\n",
    "    \n",
    "    if \"class\" in user_input or \"course\" in user_input or \"recommend\" in user_input or \"recommendation\" in user_input:\n",
    "        recs = recommendation(user_input)\n",
    "        response = f\"Here are my recommendations: {recs[0]}\"\n",
    "#         response = f\"Here are my recommendations: {recs[0]}, {recs[1]}, {recs[2]}, {recs[3]}, {recs[4]}\"\n",
    "        return response\n",
    "    else:\n",
    "        return random.choice(responses)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12a383bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "787e9205",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import ttk\n",
    "from tkinter import *\n",
    "\n",
    "root = Tk()\n",
    "root.title(\"Chatbot\")\n",
    "root.geometry(\"420x500\")\n",
    "root.resizable(width=FALSE, height=FALSE)\n",
    "\n",
    "# Create the chatbot's text area\n",
    "text_area = Text(root, bd=0, bg=\"white\", width=\"90\", height=\"20\")\n",
    "\n",
    "text_area.pack()\n",
    "\n",
    "# Create the user's input field\n",
    "input_field = Entry(root)\n",
    "\n",
    "input_field.pack()\n",
    "\n",
    "\n",
    "text_area.insert(END, f\"Chatbot: Hello there!\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# Create the send button\n",
    "send_button = Button(root, text=\"Send\", width=\"12\", height=5, bd=0, bg=\"#32de97\", activebackground=\"#3c9d9b\",fg='#ffffff',\n",
    "                     command=lambda: send_message())\n",
    "send_button.pack()\n",
    "quit_button = Button(root, text=\"Quit\", width=12, height=5, bd=0, bg=\"#de3232\", activebackground=\"#3c9d9b\",fg='#ffffff',\n",
    "                     command=lambda:root.destroy())\n",
    "quit_button.pack()\n",
    "\n",
    "\n",
    "root.bind('<Return>', lambda x: send_message())\n",
    "\n",
    "def send_message():\n",
    "  # Get the user's input\n",
    "  user_input = input_field.get()\n",
    "\n",
    "  # Clear the input field\n",
    "  input_field.delete(0, END)\n",
    "\n",
    "  # Generate a response from the chatbot\n",
    "  response = chatbot_response(user_input)\n",
    "\n",
    "\n",
    "  # Display the response in the chatbot's text area\n",
    "  text_area.insert(END, f\"User: {user_input}\\n\")\n",
    "  text_area.insert(END, f\"Chatbot: {response}\\n\")\n",
    "\n",
    "text_area.place(x=6,y=6, height=386, width=410)\n",
    "send_button.place(x=6, y=401, height=45)\n",
    "quit_button.place(x=6, y=450, height=45)\n",
    "input_field.place(x=100, y=401, height=95, width=315)\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa63573b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ec9c5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e752cb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee720bbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ca0922",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
